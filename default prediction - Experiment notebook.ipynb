{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Experiment-Notebook.png)\n# Experiment Notebook - AutoAI Notebook v1.16.0\n\n\nThis notebook contains the steps and code to demonstrate support of AutoAI experiments in Watson Machine Learning service. It introduces Python API commands for data retrieval, training experiments, persisting pipelines, testing pipelines, refining pipelines, and scoring the resulting model.\n\n**Note:** Notebook code generated using AutoAI will execute successfully. If code is modified or reordered, there is no guarantee it will successfully execute. For details, see: <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Saving an Auto AI experiment as a notebook</a>\n"}, {"metadata": {}, "cell_type": "markdown", "source": "Some familiarity with Python is helpful. This notebook uses Python 3.9 and `ibm_watson_machine_learning` package.\n\n\n## Notebook goals\n\nThe learning goals of this notebook are:\n-  Defining an AutoAI experiment\n-  Training AutoAI models \n-  Comparing trained models\n-  Deploying the model as a web service\n-  Scoring the model to generate predictions.\n\n\n\n## Contents\n\nThis notebook contains the following parts:\n\n**[Setup](#setup)**<br>\n&nbsp;&nbsp;[Package installation](#install)<br>\n&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n**[Experiment configuration](#configuration)**<br>\n&nbsp;&nbsp;[Experiment metadata](#metadata)<br>\n**[Working with completed AutoAI experiment](#work)**<br>\n&nbsp;&nbsp;[Get fitted AutoAI optimizer](#get)<br>\n&nbsp;&nbsp;[Pipelines comparison](#comparison)<br>\n&nbsp;&nbsp;[Get pipeline as scikit-learn pipeline model](#get_pipeline)<br>\n&nbsp;&nbsp;[Inspect pipeline](#inspect_pipeline)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;[Visualize pipeline model](#visualize)<br>\n&nbsp;&nbsp;&nbsp;&nbsp;[Preview pipeline model as python code](#preview)<br>\n**[Deploy and Score](#scoring)**<br>\n&nbsp;&nbsp;[Working with spaces](#working_spaces)<br>\n**[Running AutoAI experiment with Python API](#run)**<br>\n**[Clean up](#cleanup)**<br>\n**[Next steps](#next_steps)**<br>\n**[Copyrights](#copyrights)**"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"setup\"></a>\n# Setup"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"install\"></a>\n## Package installation\nBefore you use the sample code in this notebook, install the following packages:\n - ibm-watson-machine-learning,\n - autoai-libs,\n - lale,\n - scikit-learn,\n - xgboost,\n - lightgbm,\n - snapml.\n"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "!pip install ibm-watson-machine-learning | tail -n 1\n!pip install -U autoai-libs==1.13.2 | tail -n 1\n!pip install -U 'lale>=0.6,<0.7' | tail -n 1\n!pip install -U scikit-learn==1.0.2 | tail -n 1\n!pip install -U xgboost==1.5.1 | tail -n 1\n!pip install -U lightgbm==3.3.1 | tail -n 1\n!pip install -U 'snapml>=1.8.3,<1.9.0' | tail -n 1", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->ibm-watson-machine-learning) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging->autoai-libs==1.13.2) (3.0.4)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from scikit-learn->lale<0.7,>=0.6) (0.17.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from scikit-learn==1.0.2) (2.2.0)\nRequirement already satisfied: scipy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from xgboost==1.5.1) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (2.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from scikit-learn->snapml<1.9.0,>=1.8.3) (2.2.0)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"configuration\"></a>\n# Experiment configuration"}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"metadata\"></a>\n## Experiment metadata\nThis cell defines the metadata for the experiment, including: training_data_references, training_result_reference, experiment_metadata."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from ibm_watson_machine_learning.helpers import DataConnection\nfrom ibm_watson_machine_learning.helpers import ContainerLocation\n\ntraining_data_references = [\n    DataConnection(\n        data_asset_id='3e7e3f9d-5e28-417f-8f81-48773d171e27'\n    ),\n]\ntraining_result_reference = DataConnection(\n    location=ContainerLocation(\n        path='auto_ml/950085c9-069c-4333-99b4-f009cc72406b/wml_data/a6d3fb6b-fc23-4bd3-afd0-39283590075d/data/automl',\n        model_location='auto_ml/950085c9-069c-4333-99b4-f009cc72406b/wml_data/a6d3fb6b-fc23-4bd3-afd0-39283590075d/data/automl/model.zip',\n        training_status='auto_ml/950085c9-069c-4333-99b4-f009cc72406b/wml_data/a6d3fb6b-fc23-4bd3-afd0-39283590075d/training-status.json'\n    )\n)", "execution_count": 2, "outputs": []}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "experiment_metadata = dict(\n    prediction_type='binary',\n    prediction_column='DEFAULT',\n    holdout_size=0.1,\n    scoring='accuracy',\n    csv_separator=',',\n    random_state=33,\n    max_number_of_estimators=2,\n    training_data_references=training_data_references,\n    training_result_reference=training_result_reference,\n    deployment_url='https://us-south.ml.cloud.ibm.com',\n    project_id='8a6e5087-bcb4-4b74-9f30-b0b7623ec1ce',\n    positive_label='Yes',\n    drop_duplicates=True\n)", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"connection\"></a>\n## Watson Machine Learning connection\n\nThis cell defines the credentials required to work with the Watson Machine Learning service.\n\n**Action**: Please provide IBM Cloud apikey following [docs](https://cloud.ibm.com/docs/account?topic=account-userapikey)."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "api_key = 'oQ0bigzU7b3BDbp-E6MUDI-d5Itq7H1XgBv5tfOEGfij'", "execution_count": 4, "outputs": []}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "wml_credentials = {\n    \"apikey\": api_key,\n    \"url\": experiment_metadata['deployment_url']\n}", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"work\"></a>\n\n\n# Working with the completed AutoAI experiment\n\nThis cell imports the pipelines generated for the experiment so they can be compared to find the optimal pipeline to save as a model."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"get\"></a>\n\n\n## Get fitted AutoAI optimizer"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "from ibm_watson_machine_learning.experiment import AutoAI\n\npipeline_optimizer = AutoAI(wml_credentials, project_id=experiment_metadata['project_id']).runs.get_optimizer(metadata=experiment_metadata)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Use `get_params()`- to retrieve configuration parameters."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_optimizer.get_params()", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "{'name': 'default prediction',\n 'desc': 'predicting credit card defaults',\n 'prediction_type': 'classification',\n 'prediction_column': 'DEFAULT',\n 'prediction_columns': None,\n 'timestamp_column_name': None,\n 'scoring': 'accuracy',\n 'holdout_size': 0.1,\n 'max_num_daub_ensembles': 2.0,\n 't_shirt_size': 'a6c4923b-b8e4-444c-9f43-8a7ec3020110',\n 'train_sample_rows_test_size': None,\n 'include_only_estimators': None,\n 'backtest_num': None,\n 'lookback_window': None,\n 'forecast_window': None,\n 'backtest_gap_length': None,\n 'cognito_transform_names': None,\n 'data_join_graph': False,\n 'csv_separator': ',',\n 'excel_sheet': 0,\n 'encoding': 'utf-8',\n 'positive_label': None,\n 'drop_duplicates': True,\n 'text_processing': None,\n 'word2vec_feature_number': None,\n 'daub_give_priority_to_runtime': None,\n 'text_columns_names': None,\n 'n_parallel_data_connections': None,\n 'test_data_csv_separator': ',',\n 'test_data_excel_sheet': 0,\n 'test_data_encoding': 'utf-8',\n 'categorical_imputation_strategy': None,\n 'numerical_imputation_strategy': None,\n 'numerical_imputation_value': None,\n 'imputation_threshold': None,\n 'retrain_on_holdout': None,\n 'run_id': 'a6d3fb6b-fc23-4bd3-afd0-39283590075d'}"}, "metadata": {}}]}, {"metadata": {"pycharm": {"name": "#%% md\n"}}, "cell_type": "markdown", "source": "<a id=\"comparison\"></a>\n## Pipelines comparison\n\nUse the `summary()` method to list trained pipelines and evaluation metrics information in\nthe form of a Pandas DataFrame. You can use the DataFrame to compare all discovered pipelines and select the one you like for further testing."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "summary = pipeline_optimizer.summary()\nbest_pipeline_name = list(summary.index)[0]\nsummary", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "              Enhancements       Estimator  training_roc_auc  \\\nPipeline Name                                                  \nPipeline_2             HPO  LGBMClassifier          0.997302   \nPipeline_1                  LGBMClassifier          0.997161   \n\n               holdout_precision  training_average_precision  \\\nPipeline Name                                                  \nPipeline_2              0.999598                    0.973522   \nPipeline_1              0.999191                    0.991834   \n\n               holdout_average_precision  training_log_loss  holdout_recall  \\\nPipeline Name                                                                 \nPipeline_2                      0.991227           0.011845        0.973406   \nPipeline_1                      0.990081           0.029094        0.966367   \n\n               training_precision  holdout_accuracy  \\\nPipeline Name                                         \nPipeline_2               0.999776          0.997762   \nPipeline_1               0.997945          0.997145   \n\n               holdout_balanced_accuracy  training_recall  holdout_f1  \\\nPipeline Name                                                           \nPipeline_2                      0.986685         0.971364    0.986329   \nPipeline_1                      0.983148         0.968409    0.982505   \n\n               holdout_log_loss  training_accuracy_(optimized)  \\\nPipeline Name                                                    \nPipeline_2             0.012356                       0.997607   \nPipeline_1             0.031172                       0.997214   \n\n               holdout_roc_auc  training_balanced_accuracy  training_f1  \nPipeline Name                                                            \nPipeline_2            0.003651                    0.985672     0.985363  \nPipeline_1            0.003893                    0.984114     0.982951  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Enhancements</th>\n      <th>Estimator</th>\n      <th>training_roc_auc</th>\n      <th>holdout_precision</th>\n      <th>training_average_precision</th>\n      <th>holdout_average_precision</th>\n      <th>training_log_loss</th>\n      <th>holdout_recall</th>\n      <th>training_precision</th>\n      <th>holdout_accuracy</th>\n      <th>holdout_balanced_accuracy</th>\n      <th>training_recall</th>\n      <th>holdout_f1</th>\n      <th>holdout_log_loss</th>\n      <th>training_accuracy_(optimized)</th>\n      <th>holdout_roc_auc</th>\n      <th>training_balanced_accuracy</th>\n      <th>training_f1</th>\n    </tr>\n    <tr>\n      <th>Pipeline Name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pipeline_2</th>\n      <td>HPO</td>\n      <td>LGBMClassifier</td>\n      <td>0.997302</td>\n      <td>0.999598</td>\n      <td>0.973522</td>\n      <td>0.991227</td>\n      <td>0.011845</td>\n      <td>0.973406</td>\n      <td>0.999776</td>\n      <td>0.997762</td>\n      <td>0.986685</td>\n      <td>0.971364</td>\n      <td>0.986329</td>\n      <td>0.012356</td>\n      <td>0.997607</td>\n      <td>0.003651</td>\n      <td>0.985672</td>\n      <td>0.985363</td>\n    </tr>\n    <tr>\n      <th>Pipeline_1</th>\n      <td></td>\n      <td>LGBMClassifier</td>\n      <td>0.997161</td>\n      <td>0.999191</td>\n      <td>0.991834</td>\n      <td>0.990081</td>\n      <td>0.029094</td>\n      <td>0.966367</td>\n      <td>0.997945</td>\n      <td>0.997145</td>\n      <td>0.983148</td>\n      <td>0.968409</td>\n      <td>0.982505</td>\n      <td>0.031172</td>\n      <td>0.997214</td>\n      <td>0.003893</td>\n      <td>0.984114</td>\n      <td>0.982951</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"get_pipeline\"></a>\n### Get pipeline as scikit-learn pipeline model\n\nAfter you compare the pipelines, download and save a scikit-learn pipeline model object from the\nAutoAI training job.\n\n**Tip:** To get a specific pipeline pass the pipeline name in:\n```\npipeline_optimizer.get_pipeline(pipeline_name=pipeline_name)\n```"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model = pipeline_optimizer.get_pipeline()", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next, check features importance for selected pipeline."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_optimizer.get_pipeline_details()['features_importance']", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "                            features_importance\nAPPLICATION_DATE                           1.00\nSK_ID_CURR                                 0.68\nDAYS_ID_PUBLISH                            0.59\nDAYS_BIRTH                                 0.56\nAMT_ANNUITY                                0.54\n...                                         ...\nFLAG_DOCUMENT_20                           0.00\nFLAG_DOCUMENT_4                            0.00\nFLAG_DOCUMENT_8                            0.00\nFLAG_DOCUMENT_12                           0.00\nAMT_REQ_CREDIT_BUREAU_HOUR                 0.00\n\n[79 rows x 1 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features_importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>APPLICATION_DATE</th>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>SK_ID_CURR</th>\n      <td>0.68</td>\n    </tr>\n    <tr>\n      <th>DAYS_ID_PUBLISH</th>\n      <td>0.59</td>\n    </tr>\n    <tr>\n      <th>DAYS_BIRTH</th>\n      <td>0.56</td>\n    </tr>\n    <tr>\n      <th>AMT_ANNUITY</th>\n      <td>0.54</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>FLAG_DOCUMENT_20</th>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>FLAG_DOCUMENT_4</th>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>FLAG_DOCUMENT_8</th>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>FLAG_DOCUMENT_12</th>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows \u00d7 1 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "pipeline_optimizer.get_pipeline_details()", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "{'composition_steps': ['Split_TrainingHoldout',\n  'TrainingDataset_full_277430_79',\n  'Text_FE',\n  'TrainingDataset_full_277430_79',\n  'Preprocessor_default',\n  'DAUB',\n  'hpo_d'],\n 'pipeline_nodes': ['PreprocessingTransformer', 'LGBMClassifier'],\n 'ml_metrics':                                score\n training_roc_auc            0.997302\n holdout_precision           0.999598\n training_average_precision  0.973522\n holdout_average_precision   0.991227\n training_neg_log_loss      -0.011845\n holdout_recall              0.973406\n training_precision          0.999776\n holdout_accuracy            0.997762\n holdout_balanced_accuracy   0.986685\n training_recall             0.971364\n holdout_f1                  0.986329\n holdout_neg_log_loss       -0.012356\n training_accuracy           0.997607\n holdout_roc_auc             0.003651\n training_balanced_accuracy  0.985672\n training_f1                 0.985363,\n 'features_importance':                             features_importance\n APPLICATION_DATE                           1.00\n SK_ID_CURR                                 0.68\n DAYS_ID_PUBLISH                            0.59\n DAYS_BIRTH                                 0.56\n AMT_ANNUITY                                0.54\n ...                                         ...\n FLAG_DOCUMENT_20                           0.00\n FLAG_DOCUMENT_4                            0.00\n FLAG_DOCUMENT_8                            0.00\n FLAG_DOCUMENT_12                           0.00\n AMT_REQ_CREDIT_BUREAU_HOUR                 0.00\n \n [79 rows x 1 columns],\n 'confusion_matrix':             fn  fp     tn     tp\n true_class                      \n No          68   1  28268   2489\n Yes          1  68   2489  28268,\n 'roc_curve':                                     0         1         2         3   \\\n measurement types true_class                                           \n fpr               No          0.000000  0.202766  0.403941  0.504439   \n                   Yes         0.000000  0.973406  0.976144  0.978099   \n thresholds        No          1.999999  0.999957  0.999904  0.999862   \n                   Yes         2.000000  0.554221  0.219638  0.139985   \n tpr               No          0.000000  0.000391  0.001173  0.001955   \n                   Yes         0.000000  0.000035  0.000141  0.000283   \n \n                                     4         5         6         7   \\\n measurement types true_class                                           \n fpr               No          0.605540  0.657009  0.695638  0.722240   \n                   Yes         0.978882  0.980446  0.981619  0.982401   \n thresholds        No          0.999798  0.999753  0.999707  0.999673   \n                   Yes         0.122122  0.088191  0.074061  0.051630   \n tpr               No          0.002738  0.003520  0.004302  0.005084   \n                   Yes         0.000354  0.000601  0.000707  0.001167   \n \n                                     8         9   ...        21        22  \\\n measurement types true_class                      ...                       \n fpr               No          0.748346  0.814037  ...  0.993633  0.995472   \n                   Yes         0.983183  0.983966  ...  0.993352  0.994134   \n thresholds        No          0.999629  0.999459  ...  0.985922  0.981025   \n                   Yes         0.019086  0.014103  ...  0.000541  0.000371   \n tpr               No          0.005866  0.006648  ...  0.016034  0.016817   \n                   Yes         0.004528  0.006367  ...  0.185963  0.251654   \n \n                                     23        24        25        26  \\\n measurement types true_class                                           \n fpr               No          0.998833  0.999293  0.999399  0.999646   \n                   Yes         0.994916  0.995698  0.996480  0.997262   \n thresholds        No          0.951305  0.926432  0.914596  0.877882   \n                   Yes         0.000327  0.000293  0.000247  0.000202   \n tpr               No          0.017599  0.018381  0.019554  0.021118   \n                   Yes         0.277760  0.304362  0.342991  0.394460   \n \n                                     27        28        29            30  \n measurement types true_class                                              \n fpr               No          0.999717  0.999859  0.999965  1.000000e+00  \n                   Yes         0.998045  0.998827  0.999609  1.000000e+00  \n thresholds        No          0.869348  0.791336  0.530350  2.720304e-10  \n                   Yes         0.000138  0.000096  0.000043  1.194240e-06  \n tpr               No          0.021901  0.023856  0.026594  1.000000e+00  \n                   Yes         0.495561  0.596059  0.797234  1.000000e+00  \n \n [6 rows x 31 columns]}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Tip:** If you want to check all model evaluation metrics-details, use:\n```\npipeline_optimizer.get_pipeline_details()\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"inspect_pipeline\"></a>\n## Inspect pipeline"}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"visualize\"></a>\n### Visualize pipeline model\n\nPreview pipeline model stages as a graph. Each node's name links to a detailed description of the stage.\n"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.visualize()", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: cluster:(root) Pages: 1 -->\n<svg width=\"1207pt\" height=\"149pt\"\n viewBox=\"0.00 0.00 1206.91 148.54\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 144.5391)\">\n<title>cluster:(root)</title>\n<g id=\"a_graph0\"><a xlink:title=\"(root) = ...\">\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-144.5391 1202.9135,-144.5391 1202.9135,4 -4,4\"/>\n</a>\n</g>\n<!-- numpy_column_selector_0 -->\n<g id=\"node1\" class=\"node\">\n<title>numpy_column_selector_0</title>\n<g id=\"a_node1\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"numpy_column_selector_0 = NumpyColumnSelector(columns=[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 78])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"35.3553\" cy=\"-103.7696\" rx=\"35.2113\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"35.3553\" y=\"-112.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"35.3553\" y=\"-100.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"35.3553\" y=\"-88.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- compress_strings -->\n<g id=\"node2\" class=\"node\">\n<title>compress_strings</title>\n<g id=\"a_node2\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.compress_strings.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"compress_strings = CompressStrings(compress_type=&#39;hash&#39;, dtypes_list=[&#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;char_str&#39;, &#39;int_num&#39;, &#39;float_int_num&#39;, &#39;char_str&#39;, &#39;char_str&#39;, &#39;float_int_num&#39;, &#39;float_int_num&#39;, &#39;int_num&#39;, &#39;int_n...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"149.8442\" cy=\"-103.7696\" rx=\"43.2674\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"149.8442\" y=\"-106.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Compress&#45;</text>\n<text text-anchor=\"middle\" x=\"149.8442\" y=\"-94.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Strings</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_0&#45;&gt;compress_strings -->\n<g id=\"edge1\" class=\"edge\">\n<title>numpy_column_selector_0&#45;&gt;compress_strings</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M70.9527,-103.7696C79.0677,-103.7696 87.8632,-103.7696 96.5377,-103.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.617,-107.2697 106.617,-103.7696 96.6169,-100.2697 96.617,-107.2697\"/>\n</g>\n<!-- numpy_replace_missing_values_0 -->\n<g id=\"node3\" class=\"node\">\n<title>numpy_replace_missing_values_0</title>\n<g id=\"a_node3\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"numpy_replace_missing_values_0 = NumpyReplaceMissingValues(missing_values=[float(&#39;nan&#39;)], filling_values=float(&#39;nan&#39;))\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"265.0402\" cy=\"-103.7696\" rx=\"36.125\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-118.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-106.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-94.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-82.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- compress_strings&#45;&gt;numpy_replace_missing_values_0 -->\n<g id=\"edge2\" class=\"edge\">\n<title>compress_strings&#45;&gt;numpy_replace_missing_values_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M193.0667,-103.7696C201.418,-103.7696 210.2002,-103.7696 218.6478,-103.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.7348,-107.2697 228.7347,-103.7696 218.7347,-100.2697 218.7348,-107.2697\"/>\n</g>\n<!-- numpy_replace_unknown_values -->\n<g id=\"node4\" class=\"node\">\n<title>numpy_replace_unknown_values</title>\n<g id=\"a_node4\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_unknown_values.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"numpy_replace_unknown_values = NumpyReplaceUnknownValues(filling_values=float(&#39;nan&#39;), filling_values_list=[100001, 100001, 100001, 100001, 100001, 100001, float(&#39;nan&#39;), float(&#39;nan&#39;), 100001, float(&#39;nan&#39;), float(&#39;nan&#39;), 100001, 100001, float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), float(&#39;nan&#39;), floa...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"378.1148\" cy=\"-103.7696\" rx=\"41.0244\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-118.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-106.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-94.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Unknown&#45;</text>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-82.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values -->\n<g id=\"edge3\" class=\"edge\">\n<title>numpy_replace_missing_values_0&#45;&gt;numpy_replace_unknown_values</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M301.1286,-103.7696C309.3046,-103.7696 318.1401,-103.7696 326.81,-103.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"326.8624,-107.2697 336.8623,-103.7696 326.8623,-100.2697 326.8624,-107.2697\"/>\n</g>\n<!-- boolean2float -->\n<g id=\"node5\" class=\"node\">\n<title>boolean2float</title>\n<g id=\"a_node5\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.boolean2float.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"boolean2float = boolean2float()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"496.9887\" cy=\"-100.7696\" rx=\"41.7239\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"496.9887\" y=\"-97.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">boolean2float</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_unknown_values&#45;&gt;boolean2float -->\n<g id=\"edge4\" class=\"edge\">\n<title>numpy_replace_unknown_values&#45;&gt;boolean2float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M419.3575,-102.7287C427.5574,-102.5218 436.2686,-102.3019 444.7792,-102.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"445.1044,-105.5802 455.0129,-101.8289 444.9277,-98.5824 445.1044,-105.5802\"/>\n</g>\n<!-- cat_imputer -->\n<g id=\"node6\" class=\"node\">\n<title>cat_imputer</title>\n<g id=\"a_node6\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_imputer.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"cat_imputer = CatImputer(missing_values=float(&#39;nan&#39;), sklearn_version_family=&#39;1&#39;, strategy=&#39;most_frequent&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"607.3773\" cy=\"-98.7696\" rx=\"32.5538\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"607.3773\" y=\"-101.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"607.3773\" y=\"-89.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- boolean2float&#45;&gt;cat_imputer -->\n<g id=\"edge5\" class=\"edge\">\n<title>boolean2float&#45;&gt;cat_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M539.0368,-100.0077C547.4403,-99.8555 556.2755,-99.6954 564.6999,-99.5428\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.7807,-103.042 574.7156,-99.3613 564.6539,-96.0431 564.7807,-103.042\"/>\n</g>\n<!-- cat_encoder -->\n<g id=\"node7\" class=\"node\">\n<title>cat_encoder</title>\n<g id=\"a_node7\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.cat_encoder.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"cat_encoder = CatEncoder(encoding=&#39;ordinal&#39;, categories=&#39;auto&#39;, dtype=np.float64, handle_unknown=&#39;error&#39;, sklearn_version_family=&#39;1&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"715.5022\" cy=\"-97.7696\" rx=\"33.8824\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"715.5022\" y=\"-100.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Cat&#45;</text>\n<text text-anchor=\"middle\" x=\"715.5022\" y=\"-88.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Encoder</text>\n</a>\n</g>\n</g>\n<!-- cat_imputer&#45;&gt;cat_encoder -->\n<g id=\"edge6\" class=\"edge\">\n<title>cat_imputer&#45;&gt;cat_encoder</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M640.1118,-98.4668C649.9014,-98.3763 660.8022,-98.2754 671.2041,-98.1792\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"671.413,-101.6776 681.3801,-98.0851 671.3482,-94.6779 671.413,-101.6776\"/>\n</g>\n<!-- float32_transform_0 -->\n<g id=\"node8\" class=\"node\">\n<title>float32_transform_0</title>\n<g id=\"a_node8\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"float32_transform_0 = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"829.9911\" cy=\"-94.7696\" rx=\"38.7821\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"829.9911\" y=\"-97.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"829.9911\" y=\"-85.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- cat_encoder&#45;&gt;float32_transform_0 -->\n<g id=\"edge7\" class=\"edge\">\n<title>cat_encoder&#45;&gt;float32_transform_0</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M749.5427,-96.8776C759.4329,-96.6184 770.4356,-96.3301 781.0492,-96.052\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"781.152,-99.5506 791.0569,-95.7898 780.9686,-92.553 781.152,-99.5506\"/>\n</g>\n<!-- concat_features -->\n<g id=\"node15\" class=\"node\">\n<title>concat_features</title>\n<g id=\"a_node15\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.rasl.concat_features.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"concat_features = ConcatFeatures()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"940.9444\" cy=\"-68.7696\" rx=\"36.125\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"940.9444\" y=\"-71.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Concat&#45;</text>\n<text text-anchor=\"middle\" x=\"940.9444\" y=\"-59.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Features</text>\n</a>\n</g>\n</g>\n<!-- float32_transform_0&#45;&gt;concat_features -->\n<g id=\"edge13\" class=\"edge\">\n<title>float32_transform_0&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M865.4025,-86.4715C875.6875,-84.0614 887.0359,-81.4021 897.7422,-78.8933\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"898.8169,-82.2363 907.7546,-76.547 897.2198,-75.4209 898.8169,-82.2363\"/>\n</g>\n<!-- numpy_column_selector_1 -->\n<g id=\"node9\" class=\"node\">\n<title>numpy_column_selector_1</title>\n<g id=\"a_node9\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_column_selector.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"numpy_column_selector_1 = NumpyColumnSelector(columns=[0, 1, 2, 3, 15, 16, 17, 18, 19, 24, 25, 26, 72, 75, 76, 77])\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"265.0402\" cy=\"-31.7696\" rx=\"35.2113\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-40.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-28.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Column&#45;</text>\n<text text-anchor=\"middle\" x=\"265.0402\" y=\"-16.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Selector</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float -->\n<g id=\"node10\" class=\"node\">\n<title>float_str2_float</title>\n<g id=\"a_node10\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float_str2_float.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"float_str2_float = FloatStr2Float(dtypes_list=[&#39;float_int_num&#39;, &#39;int_num&#39;, &#39;float_int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;int_num&#39;, &#39;float_int_num&#39;, &#39;int_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;, &#39;int_num&#39;, &#39;float_num&#39;, &#39;float_num&#39;], missing_values_reference_list=[f...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"378.1148\" cy=\"-31.7696\" rx=\"27\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-40.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Float&#45;</text>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-28.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Str2&#45;</text>\n<text text-anchor=\"middle\" x=\"378.1148\" y=\"-16.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Float</text>\n</a>\n</g>\n</g>\n<!-- numpy_column_selector_1&#45;&gt;float_str2_float -->\n<g id=\"edge8\" class=\"edge\">\n<title>numpy_column_selector_1&#45;&gt;float_str2_float</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M300.5074,-31.7696C313.3861,-31.7696 327.9669,-31.7696 340.9852,-31.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"341.0284,-35.2697 351.0284,-31.7696 341.0283,-28.2697 341.0284,-35.2697\"/>\n</g>\n<!-- numpy_replace_missing_values_1 -->\n<g id=\"node11\" class=\"node\">\n<title>numpy_replace_missing_values_1</title>\n<g id=\"a_node11\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_replace_missing_values.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"numpy_replace_missing_values_1 = NumpyReplaceMissingValues(missing_values=[float(&#39;nan&#39;)], filling_values=float(&#39;nan&#39;))\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"496.9887\" cy=\"-36.7696\" rx=\"36.125\" ry=\"36.5405\"/>\n<text text-anchor=\"middle\" x=\"496.9887\" y=\"-51.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"496.9887\" y=\"-39.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Replace&#45;</text>\n<text text-anchor=\"middle\" x=\"496.9887\" y=\"-27.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Missing&#45;</text>\n<text text-anchor=\"middle\" x=\"496.9887\" y=\"-15.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Values</text>\n</a>\n</g>\n</g>\n<!-- float_str2_float&#45;&gt;numpy_replace_missing_values_1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>float_str2_float&#45;&gt;numpy_replace_missing_values_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M405.3869,-32.9167C418.7534,-33.4789 435.2256,-34.1717 450.4989,-34.8141\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"450.6901,-38.3252 460.8283,-35.2486 450.9843,-31.3314 450.6901,-38.3252\"/>\n</g>\n<!-- num_imputer -->\n<g id=\"node12\" class=\"node\">\n<title>num_imputer</title>\n<g id=\"a_node12\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.num_imputer.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"num_imputer = NumImputer(missing_values=float(&#39;nan&#39;), strategy=&#39;median&#39;)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"607.3773\" cy=\"-39.7696\" rx=\"32.5538\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"607.3773\" y=\"-42.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Num&#45;</text>\n<text text-anchor=\"middle\" x=\"607.3773\" y=\"-30.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Imputer</text>\n</a>\n</g>\n</g>\n<!-- numpy_replace_missing_values_1&#45;&gt;num_imputer -->\n<g id=\"edge10\" class=\"edge\">\n<title>numpy_replace_missing_values_1&#45;&gt;num_imputer</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M533.1341,-37.7519C543.2261,-38.0261 554.2866,-38.3267 564.7167,-38.6102\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.786,-42.1133 574.8774,-38.8863 564.9762,-35.1158 564.786,-42.1133\"/>\n</g>\n<!-- opt_standard_scaler -->\n<g id=\"node13\" class=\"node\">\n<title>opt_standard_scaler</title>\n<g id=\"a_node13\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.opt_standard_scaler.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"opt_standard_scaler = OptStandardScaler(use_scaler_flag=False)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"715.5022\" cy=\"-41.7696\" rx=\"39.6962\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"715.5022\" y=\"-50.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Opt&#45;</text>\n<text text-anchor=\"middle\" x=\"715.5022\" y=\"-38.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Standard&#45;</text>\n<text text-anchor=\"middle\" x=\"715.5022\" y=\"-26.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Scaler</text>\n</a>\n</g>\n</g>\n<!-- num_imputer&#45;&gt;opt_standard_scaler -->\n<g id=\"edge11\" class=\"edge\">\n<title>num_imputer&#45;&gt;opt_standard_scaler</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M640.1118,-40.375C648.1533,-40.5238 656.9445,-40.6864 665.5931,-40.8464\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"665.5638,-44.3463 675.6268,-41.032 665.6933,-37.3475 665.5638,-44.3463\"/>\n</g>\n<!-- float32_transform_1 -->\n<g id=\"node14\" class=\"node\">\n<title>float32_transform_1</title>\n<g id=\"a_node14\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.float32_transform.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"float32_transform_1 = float32_transform()\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"829.9911\" cy=\"-45.7696\" rx=\"38.7821\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"829.9911\" y=\"-48.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">float32_&#45;</text>\n<text text-anchor=\"middle\" x=\"829.9911\" y=\"-36.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">transform</text>\n</a>\n</g>\n</g>\n<!-- opt_standard_scaler&#45;&gt;float32_transform_1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>opt_standard_scaler&#45;&gt;float32_transform_1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M755.2236,-43.1573C763.4883,-43.4461 772.2924,-43.7537 780.8499,-44.0527\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"780.9969,-47.5598 791.1131,-44.4112 781.2414,-40.5641 780.9969,-47.5598\"/>\n</g>\n<!-- float32_transform_1&#45;&gt;concat_features -->\n<g id=\"edge14\" class=\"edge\">\n<title>float32_transform_1&#45;&gt;concat_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M866.0144,-53.237C875.8856,-55.2832 886.6976,-57.5245 896.9608,-59.652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"896.4835,-63.1274 906.9858,-61.7301 897.9044,-56.2731 896.4835,-63.1274\"/>\n</g>\n<!-- numpy_permute_array -->\n<g id=\"node16\" class=\"node\">\n<title>numpy_permute_array</title>\n<g id=\"a_node16\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.autoai_libs.numpy_permute_array.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"numpy_permute_array = NumpyPermuteArray(axis=0, permutation_indices=[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 6...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1051.1906\" cy=\"-68.7696\" rx=\"38.3684\" ry=\"28.0702\"/>\n<text text-anchor=\"middle\" x=\"1051.1906\" y=\"-77.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Numpy&#45;</text>\n<text text-anchor=\"middle\" x=\"1051.1906\" y=\"-65.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Permute&#45;</text>\n<text text-anchor=\"middle\" x=\"1051.1906\" y=\"-53.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Array</text>\n</a>\n</g>\n</g>\n<!-- concat_features&#45;&gt;numpy_permute_array -->\n<g id=\"edge15\" class=\"edge\">\n<title>concat_features&#45;&gt;numpy_permute_array</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M977.0431,-68.7696C985.1686,-68.7696 993.9226,-68.7696 1002.4686,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1002.7335,-72.2697 1012.7334,-68.7696 1002.7334,-65.2697 1002.7335,-72.2697\"/>\n</g>\n<!-- lgbm_classifier -->\n<g id=\"node17\" class=\"node\">\n<title>lgbm_classifier</title>\n<g id=\"a_node17\"><a xlink:href=\"https://lale.readthedocs.io/en/latest/modules/lale.lib.lightgbm.lgbm_classifier.html\" target=\"_blank\" rel=\"noopener noreferrer\" xlink:title=\"lgbm_classifier = LGBMClassifier(class_weight=&#39;balanced&#39;, colsample_bytree=0.5185878473906118, learning_rate=0.2819183874082652, min_child_samples=16, min_child_weight=0.007076389406189793, n_estimators=992, n_jobs=2, num_leaves=64, random_state=33, reg_alpha=0.9288233666023282, reg_l...)\">\n<ellipse fill=\"#ffffff\" stroke=\"#000000\" cx=\"1162.1439\" cy=\"-68.7696\" rx=\"36.5405\" ry=\"19.6\"/>\n<text text-anchor=\"middle\" x=\"1162.1439\" y=\"-71.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">LGBM&#45;</text>\n<text text-anchor=\"middle\" x=\"1162.1439\" y=\"-59.9696\" font-family=\"Times,serif\" font-size=\"11.00\" fill=\"#000000\">Classifier</text>\n</a>\n</g>\n</g>\n<!-- numpy_permute_array&#45;&gt;lgbm_classifier -->\n<g id=\"edge16\" class=\"edge\">\n<title>numpy_permute_array&#45;&gt;lgbm_classifier</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1089.3745,-68.7696C1097.5745,-68.7696 1106.3345,-68.7696 1114.8332,-68.7696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1115.0149,-72.2697 1125.0149,-68.7696 1115.0149,-65.2697 1115.0149,-72.2697\"/>\n</g>\n</g>\n</svg>\n", "text/plain": "<graphviz.graphs.Digraph at 0x7ff519e4cd60>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"preview\"></a>\n### Preview pipeline model as Python code\nIn the next cell, you can preview the saved pipeline model as Python code.  \nYou can review the exact steps used to create the model.\n\n**Note:** If you want to get sklearn representation, add the following parameter to `pretty_print` call: `astype='sklearn'`."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "pipeline_model.pretty_print(combinators=False, ipython_display=True)", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.Markdown object>", "text/markdown": "```python\nfrom autoai_libs.transformers.exportable import NumpyColumnSelector\nfrom autoai_libs.transformers.exportable import CompressStrings\nfrom autoai_libs.transformers.exportable import NumpyReplaceMissingValues\nfrom autoai_libs.transformers.exportable import NumpyReplaceUnknownValues\nfrom autoai_libs.transformers.exportable import boolean2float\nfrom autoai_libs.transformers.exportable import CatImputer\nfrom autoai_libs.transformers.exportable import CatEncoder\nimport numpy as np\nfrom autoai_libs.transformers.exportable import float32_transform\nfrom lale.operators import make_pipeline\nfrom autoai_libs.transformers.exportable import FloatStr2Float\nfrom autoai_libs.transformers.exportable import NumImputer\nfrom autoai_libs.transformers.exportable import OptStandardScaler\nfrom lale.operators import make_union\nfrom autoai_libs.transformers.exportable import NumpyPermuteArray\nfrom lightgbm.sklearn import LGBMClassifier\n\nnumpy_column_selector_0 = NumpyColumnSelector(\n    columns=[\n        4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 27, 28, 29, 30,\n        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n        65, 66, 67, 68, 69, 70, 71, 73, 74, 78,\n    ]\n)\ncompress_strings = CompressStrings(\n    compress_type=\"hash\",\n    dtypes_list=[\n        \"float_int_num\", \"float_int_num\", \"float_int_num\", \"float_int_num\",\n        \"float_int_num\", \"float_int_num\", \"char_str\", \"int_num\",\n        \"float_int_num\", \"char_str\", \"char_str\", \"float_int_num\",\n        \"float_int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"char_str\", \"char_str\",\n        \"int_num\", \"int_num\", \"int_num\", \"char_str\", \"char_str\", \"char_str\",\n        \"char_str\", \"char_str\", \"char_str\", \"char_str\", \"float_int_num\",\n        \"float_int_num\", \"char_str\", \"char_str\", \"float_int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"char_str\",\n    ],\n    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n    misslist_list=[\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [],\n        [float(\"nan\")],\n        [],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],\n        [], [], [], [], [], [], [], [], [], [], [], [], [], [],\n        [float(\"nan\")],\n        [], [], [], [], [],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [float(\"nan\")],\n        [],\n        [float(\"nan\")],\n        [], [], [], [], [], [], [],\n    ],\n)\nnumpy_replace_missing_values_0 = NumpyReplaceMissingValues(\n    missing_values=[float(\"nan\")], filling_values=float(\"nan\")\n)\nnumpy_replace_unknown_values = NumpyReplaceUnknownValues(\n    filling_values=float(\"nan\"),\n    filling_values_list=[\n        100001, 100001, 100001, 100001, 100001, 100001, float(\"nan\"),\n        float(\"nan\"), 100001, float(\"nan\"), float(\"nan\"), 100001, 100001,\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), 100001, 100001,\n        float(\"nan\"), float(\"nan\"), 100001, float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n    ],\n    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n)\ncat_imputer = CatImputer(\n    missing_values=float(\"nan\"),\n    sklearn_version_family=\"1\",\n    strategy=\"most_frequent\",\n)\ncat_encoder = CatEncoder(\n    encoding=\"ordinal\",\n    categories=\"auto\",\n    dtype=np.float64,\n    handle_unknown=\"error\",\n    sklearn_version_family=\"1\",\n)\npipeline_0 = make_pipeline(\n    numpy_column_selector_0,\n    compress_strings,\n    numpy_replace_missing_values_0,\n    numpy_replace_unknown_values,\n    boolean2float(),\n    cat_imputer,\n    cat_encoder,\n    float32_transform(),\n)\nnumpy_column_selector_1 = NumpyColumnSelector(\n    columns=[0, 1, 2, 3, 15, 16, 17, 18, 19, 24, 25, 26, 72, 75, 76, 77]\n)\nfloat_str2_float = FloatStr2Float(\n    dtypes_list=[\n        \"float_int_num\", \"int_num\", \"float_int_num\", \"int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"float_int_num\", \"int_num\", \"float_num\",\n        \"float_num\", \"float_num\", \"float_num\", \"int_num\", \"float_num\",\n        \"float_num\",\n    ],\n    missing_values_reference_list=[float(\"nan\")],\n)\nnumpy_replace_missing_values_1 = NumpyReplaceMissingValues(\n    missing_values=[float(\"nan\")], filling_values=float(\"nan\")\n)\nnum_imputer = NumImputer(missing_values=float(\"nan\"), strategy=\"median\")\nopt_standard_scaler = OptStandardScaler(use_scaler_flag=False)\npipeline_1 = make_pipeline(\n    numpy_column_selector_1,\n    float_str2_float,\n    numpy_replace_missing_values_1,\n    num_imputer,\n    opt_standard_scaler,\n    float32_transform(),\n)\nunion = make_union(pipeline_0, pipeline_1)\nnumpy_permute_array = NumpyPermuteArray(\n    axis=0,\n    permutation_indices=[\n        4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 21, 22, 23, 27, 28, 29, 30,\n        31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n        65, 66, 67, 68, 69, 70, 71, 73, 74, 78, 0, 1, 2, 3, 15, 16, 17, 18,\n        19, 24, 25, 26, 72, 75, 76, 77,\n    ],\n)\nlgbm_classifier = LGBMClassifier(\n    class_weight=\"balanced\",\n    colsample_bytree=0.5185878473906118,\n    learning_rate=0.2819183874082652,\n    min_child_samples=16,\n    min_child_weight=0.007076389406189793,\n    n_estimators=992,\n    n_jobs=2,\n    num_leaves=64,\n    random_state=33,\n    reg_alpha=0.9288233666023282,\n    reg_lambda=0.551821503605106,\n    subsample=0.9955253005922045,\n    subsample_freq=1,\n)\npipeline = make_pipeline(union, numpy_permute_array, lgbm_classifier)\n```"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Calling the `predict` method\nIf you want to get a prediction using pipeline model object, call `pipeline_model.predict()`.\n\n**Note:** If you want to work with pure sklearn model:\n - add the following parameter to `get_pipeline` call: `astype='sklearn'`,\n - or `scikit_learn_pipeline = pipeline_model.export_to_sklearn_pipeline()`"}, {"metadata": {}, "cell_type": "code", "source": "pipeline_model.predict()", "execution_count": 14, "outputs": [{"output_type": "error", "ename": "TypeError", "evalue": "predict() missing 1 required positional argument: 'X'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m/tmp/wsuser/ipykernel_369/2386711910.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'X'"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"scoring\"></a>\n## Deploy and Score\n\nIn this section you will learn how to deploy and score the model as a web service."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"working_spaces\"></a>\n### Working with spaces\n\nIn this section you will specify a deployment space for organizing the assets for deploying and scoring the model. If you do not have an existing space, you can use [Deployment Spaces Dashboard](https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas) to create a new space, following these steps:\n\n- Click **New Deployment Space**.\n- Create an empty space.\n- Select Cloud Object Storage.\n- Select Watson Machine Learning instance and press **Create**.\n- Copy `space_id` and paste it below.\n\n**Tip**: You can also use the API to prepare the space for your work. Learn more [here](https://github.com/IBM/watson-machine-learning-samples/blob/master/notebooks/python_sdk/instance-management/Space%20management.ipynb).\n\n**Action**: assign or update space ID below."}, {"metadata": {}, "cell_type": "markdown", "source": "### Deployment creation"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "target_space_id = \"1e655876-eb44-483b-bcbd-623a4499f87a\"\n\nfrom ibm_watson_machine_learning.deployment import WebService\n\nservice = WebService(\n    source_wml_credentials=wml_credentials,\n    target_wml_credentials=wml_credentials,\n    source_project_id=experiment_metadata['project_id'],\n    target_space_id=target_space_id\n)\nservice.create(\n    model=best_pipeline_name,\n    metadata=experiment_metadata,\n    deployment_name='Best_pipeline_webservice'\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Use the `print` method for the deployment object to show basic information about the service: "}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "print(service)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "To show all available information about the deployment use the `.get_params()` method."}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "code", "source": "service.get_params()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Scoring of webservice\nYou can make scoring request by calling `score()` on the deployed pipeline."}, {"metadata": {}, "cell_type": "code", "source": "service = WebService(target_wml_credentials=wml_credentials,target_space_id=experiment_metadata['1e655876-eb44-483b-bcbd-623a4499f87a'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "If you want to work with the web service in an external Python application, follow these steps to retrieve the service object:\n\n - Initialize the service by `service = WebService(target_wml_credentials=wml_credentials,target_space_id=experiment_metadata['space_id'])`\n - Get deployment_id by `service.list()` method\n - Get webservice object by `service.get('deployment_id')` method\n\nAfter that you can call `service.score(score_records_df)` method. The `score()` method accepts `pandas.DataFrame` object. "}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"cleanup\"></a>\n### Deleting deployment\nYou can delete the existing deployment by calling the `service.delete()` command.\nTo list the existing web services, use `service.list()`."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"run\"></a>\n\n## Running AutoAI experiment with Python API"}, {"metadata": {}, "cell_type": "markdown", "source": "If you want to run the AutoAI experiment using the Python API, follow these. The experiment settings were generated basing on parameters set in the AutoAI UI.\n"}, {"metadata": {"pycharm": {"name": "#%%\n"}}, "cell_type": "markdown", "source": "```\nfrom ibm_watson_machine_learning.experiment import AutoAI\n\nexperiment = AutoAI(wml_credentials, project_id=experiment_metadata['project_id'])\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "```\nOPTIMIZER_NAME = 'custom_name'\n```"}, {"metadata": {"pycharm": {"name": "#%% raw\n"}}, "cell_type": "markdown", "source": "```\nfrom ibm_watson_machine_learning.helpers import DataConnection\nfrom ibm_watson_machine_learning.helpers import ContainerLocation\n\ntraining_data_references = [\n    DataConnection(\n        data_asset_id='3e7e3f9d-5e28-417f-8f81-48773d171e27'\n    ),\n]\ntraining_result_reference = DataConnection(\n    location=ContainerLocation(\n        path='auto_ml/950085c9-069c-4333-99b4-f009cc72406b/wml_data/a6d3fb6b-fc23-4bd3-afd0-39283590075d/data/automl',\n        model_location='auto_ml/950085c9-069c-4333-99b4-f009cc72406b/wml_data/a6d3fb6b-fc23-4bd3-afd0-39283590075d/data/automl/model.zip',\n        training_status='auto_ml/950085c9-069c-4333-99b4-f009cc72406b/wml_data/a6d3fb6b-fc23-4bd3-afd0-39283590075d/training-status.json'\n    )\n)\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "The new pipeline optimizer will be created and training will be triggered."}, {"metadata": {"pycharm": {"name": "#%%raw\n"}}, "cell_type": "markdown", "source": "```\npipeline_optimizer = experiment.optimizer(\n    name=OPTIMIZER_NAME,\n    prediction_type=experiment_metadata['prediction_type'],\n    prediction_column=experiment_metadata['prediction_column'],\n    scoring=experiment_metadata['scoring'],\n    holdout_size=experiment_metadata['holdout_size'],\n    csv_separator=experiment_metadata['csv_separator'],\n    positive_label=experiment_metadata['positive_label'],\n    drop_duplicates=experiment_metadata['drop_duplicates'],\n)\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "```\npipeline_optimizer.fit(\n    training_data_references=training_data_references,\n    training_results_reference=training_result_reference,\n)\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "\n<a id=\"next_steps\"></a>\n# Next steps\nYou successfully completed this notebook!\nYou learned how to use ibm-watson-machine-learning to run and explore AutoAI experiments.\nCheck out our [Online Documentation](https://www.ibm.com/cloud/watson-studio/autoai) for more samples, tutorials, documentation, how-tos, and blog posts."}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2022 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for Watson Studio Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"http://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\">License Terms</a>  \n\n___"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "pycharm": {"stem_cell": {"cell_type": "raw", "source": ["\n"], "metadata": {"collapsed": false}}}}, "nbformat": 4, "nbformat_minor": 1}